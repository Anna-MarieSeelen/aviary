onsuccess:
    print("Assembly finished, no error")

onerror:
    print("An error occurred")

onstart:
    import os
    import sys


    from snakemake.utils import logger, min_version

    sys.path.append(os.path.join(os.path.dirname(os.path.abspath(workflow.snakefile)),"../scripts"))

    # minimum required snakemake version
    min_version("6.0")
    long_reads = config["long_reads"]
    fasta = config["fasta"]
    short_reads_1 = config["short_reads_1"]
    short_reads_2 = config["short_reads_2"]
    threads = config["max_threads"]
    ## pplacer deadlocks on too many threads
    pplacer_threads = min(48, int(config["pplacer_threads"]))
    import os
    import sys

    if long_reads == "none" and short_reads_1 == "none":
        sys.exit("Need at least one of long_reads or short_reads_1")
    if long_reads != "none" and not os.path.exists(long_reads[0]):
        sys.exit("long_reads does not point to a file")
    if short_reads_1 != "none" and not os.path.exists(short_reads_1[0]):
        sys.exit("short_reads_1 does not point to a file")
    if short_reads_2 != "none" and not os.path.exists(short_reads_2[0]):
        sys.exit("short_reads_2 does not point to a file")
    if gtdbtk_folder != "none" and not os.path.exists(gtdbtk_folder):
        sys.stderr.write("gtdbtk_folder does not point to a folder\n")
    if busco_folder != "none" and not os.path.exists(busco_folder):
        sys.stderr.write("busco_folder does not point to a folder\n")
    
# Filter reads against a reference, i.e. for removing host contamination from the metagenome
rule map_reads_ref:
    input:
        fastq = config["long_reads"],
        reference_filter= config["reference_filter"]
    output:
        "data/raw_mapped_ref.bam"
    conda:
        "../envs/coverm.yaml"
    threads:
         config["max_threads"]
    shell:
        "minimap2 -ax map-ont -t {threads} {input.reference_filter} {input.fastq} | samtools view -b  > {output}"


# Get a list of reads that don't map to genome you want to filter
rule get_umapped_reads_ref:
    input:
        "data/raw_mapped_ref.bam"
    output:
        "data/unmapped_to_ref.list"
    params:
        "no_full"
    conda:
        "../envs/pysam.yaml"
    script:
        "../scripts/filter_read_list.py"


# Create new read file with filtered reads
rule get_reads_list_ref:
    input:
        fastq = config["long_reads"],
        list = "data/unmapped_to_ref.list"
    output:
        "data/long_reads.fastq.gz"
    conda:
        "../envs/seqtk.yaml"
    shell:
        "seqtk subseq {input.fastq} {input.list} | gzip > {output}"


# Assembly long reads with metaflye
rule flye_assembly:
    input:
        fastq = "data/long_reads.fastq.gz"
    output:
        fasta = "data/flye/assembly.fasta",
        graph = "data/flye/assembly_graph.gfa",
        info = "data/flye/assembly_info.txt"
    params:
        genome_size = config["meta_genome_size"]
    conda:
        "../envs/flye.yaml"
    threads:
        config["max_threads"]
    shell:
        "flye --nano-raw {input.fastq} --meta -o data/flye -t {threads} -g {params.genome_size}"


# Polish the long reads assembly with Racon
rule polish_metagenome_racon:
    input:
        fastq = "data/long_reads.fastq.gz",
        fasta = "data/flye/assembly.fasta"
    conda:
        "../envs/racon.yaml"
    threads:
        config["max_threads"]
    params:
        prefix = "racon",
        maxcov = 200,
        rounds = 3,
        illumina = False
    output:
        fasta = "data/assembly.pol.rac.fasta"
    script:
        "../scripts/racon_polish.py"


### Steps if illumina data exists
rule filter_illumina_ref:
    input:
        fastq_1 = config["short_reads_1"],
        fastq_2 = config["short_reads_2"],
        reference_filter = config["reference_filter"]
    output:
        bam = "data/short_unmapped_ref.bam",
        fastq = "data/short_reads.fastq.gz"
    conda:
        "../envs/minimap2.yaml"
    threads:
         config["max_threads"]
    shell:
        """
        minimap2 -ax sr -t {threads} {input.reference_filter} {input.fastq_1} {input.fastq_2}  |
        samtools view -b -f 12 > {output.bam} && \
        samtools bam2fq {output.bam} | gzip > {output.fastq}
        """


rule filter_illumina_ref_interleaved:
    input:
        fastq_1 = config["short_reads_1"],
        reference_filter = config["reference_filter"]
    output:
        bam = "data/short_unmapped_ref.bam",
        fastq = "data/short_reads.fastq.gz"
    conda:
        "../envs/minimap2.yaml"
    threads:
         config["max_threads"]
    shell:
        """
        minimap2 -ax sr -t {threads} {input.reference_filter} {input.fastq_1} |
        samtools view -b -f 12 > {output.bam} && \
        samtools bam2fq {output.bam} | gzip > {output.fastq}
        """


# The racon polished long read assembly is polished again with the short reads using Pilon
rule polish_meta_pilon:
    input:
        reads = "data/short_reads.fastq.gz",
        fasta = "data/assembly.pol.rac.fasta"
    output:
        fasta = "data/assembly.pol.pil.fasta",
        bam = "data/pilon.sort.bam"
    threads:
        config["max_threads"]
    params:
        pilon_memory = config["pilon_memory"]
    conda:
        "../envs/pilon.yaml"
    shell:
        """
        minimap2 -ax sr -t {threads} {input.fasta} {input.reads} | samtools view -b | 
        samtools sort -o {output.bam} - && \
        samtools index {output.bam} && \
        pilon -Xmx{params.pilon_memory}000m --genome {input.fasta} --frags data/pilon.sort.bam \
        --threads {threads} --output data/assembly.pol.pil --fix bases
        """


# The assembly polished with Racon and Pilon is polished again with the short reads using Racon
rule polish_meta_racon_ill:
    input:
        fastq = "data/short_reads.fastq.gz",
        fasta = "data/assembly.pol.pil.fasta"
    output:
        fasta = "data/assembly.pol.fin.fasta",
        paf = "data/racon_polishing/alignment.racon_ill.0.paf"
    threads:
        config["max_threads"]
    conda:
        "../envs/racon.yaml"
    params:
        prefix = "racon_ill",
        maxcov = 200,
        rounds = 1,
        illumina = True
    script:
        "../scripts/racon_polish.py"


# High coverage contigs are identified
rule get_high_cov_contigs:
    input:
        info = "data/flye/assembly_info.txt",
        fasta = "data/assembly.pol.fin.fasta",
        graph = "data/flye/assembly_graph.gfa",
        paf = "data/racon_polishing/alignment.racon_ill.0.paf"
    output:
        fasta = "data/flye_high_cov.fasta"
    params:
        min_cov_long = 20.0,
        min_cov_short = 10.0,
        short_contig_size = 200000,
        long_contig_size = 500000
    run:
        ill_cov_dict = {}
        with open(input.paf) as paf:
            for line in paf:
                query, qlen, qstart, qend, strand, ref, rlen, rstart, rend = line.split()[:9]
                ref = ref[:-6]
                if not ref in ill_cov_dict:
                    ill_cov_dict[ref] = 0.0
                ill_cov_dict[ref] += (int(rend) - int(rstart)) / int(rlen)
        count = 0
        with open(input.info) as f:
            f.readline()
            high_cov_set = set()
            short_edges = {}
            for line in f:
                if int(line.split()[1]) > params.long_contig_size:
                    high_cov_set.add(line.split()[0])
                elif int(line.split()[1]) < params.short_contig_size:
                    se1 = line.split()[6].split(',')[0]
                    if se1.startswith('-'):
                        se1 = ("edge_" + se1[1:], True)
                    else:
                        se1 = ("edge_" + se1, False)
                    se2 = line.split()[6].split(',')[-1]
                    if se2.startswith('-'):
                        se2 = ("edge_" + se2[1:], False)
                    else:
                        se2 = ("edge_" + se2, True)
                    if not se1 in short_edges:
                        short_edges[se1] = []
                    short_edges[se1].append(line.split()[0])
                    if not se2 in short_edges:
                        short_edges[se2] = []
                    short_edges[se2].append(line.split()[0])
                if float(line.split()[2]) >= params.min_cov_long or not line.split()[0] in ill_cov_dict or ill_cov_dict[line.split()[0]] <= params.min_cov_short:
                    high_cov_set.add(line.split()[0])
        with open(input.graph) as f:
            filtered_contigs = set()
            for line in f:
                if line.startswith("L"):
                    if (line.split()[1], line.split()[2] == '+') in short_edges and (line.split()[3], line.split()[4] == '-') in short_edges and not line.split()[1] == line.split()[3]:
                        for i in short_edges[(line.split()[1], line.split()[2] == '+')]:
                            filtered_contigs.add(i)
                        for i in short_edges[(line.split()[3], line.split()[4] == '-')]:
                            filtered_contigs.add(i)
        for i in filtered_contigs:
            try:
                high_cov_set.remove(i)
            except KeyError:
                pass
        with open(input.fasta) as f, open(output.fasta, 'w') as o:
            write_line = False
            for line in f:
                if line.startswith('>') and line.split()[0][1:-6] in high_cov_set:
                    write_line = True
                elif line.startswith('>'):
                    write_line = False
                if write_line:
                    o.write(line)


# Illumina reads are filtered against the nanopore assembly.
# Specifically, short reads that do not map to the high coverage long contigs are collected
rule filter_illumina_assembly:
    input:
        reference = "data/flye_high_cov.fasta",
        fastq = "data/short_reads.fastq.gz"
    output:
        bam = "data/sr_vs_long.sort.bam",
        fastq = "data/short_reads.filt.fastq.gz"
    conda:
        "../envs/minimap2.yaml"
    threads:
         config["max_threads"]
    shell:
        """
        minimap2 -ax sr -t {threads} {input.reference} {input.fastq} |  samtools view -b |
        samtools sort -o {output.bam} - && \
        samtools index {output.bam} && \
        samtools bam2fq -f 12 {output.bam} | gzip > {output.fastq}
        """

# If unassembled long reads are provided, skip the long read assembly
rule skip_long_assembly:
    input:
        fastq = "data/short_reads.fastq.gz",
        unassembled_long = config["unassembled_long"]
    output:
        fastq = "data/short_reads.filt.fastq.gz",
        fasta = "data/flye_high_cov.fasta",
        long_reads = "data/long_reads.fastq.gz"
    shell:
        """
        ln {input.fastq} {output.fastq} && \
        touch {output.fasta} && \
        ln {input.unassembled_long} {output.long_reads}
        """


# If only short reads are provided
rule short_only:
    input:
        fastq = "data/short_reads.fastq.gz"
    output:
        fastq = "data/short_reads.filt.fastq.gz",
        fasta = "data/flye_high_cov.fasta",
        long_reads = "data/long_reads.fastq.gz"
    shell:
        """
        ln {input.fastq} {output.fastq} && \
        touch {output.fasta} && \
        touch {output.long_reads}
        """

# Short reads that did not map to the long read assembly are hybrid assembled with metaspades
# If no long reads were provided, long_reads.fastq.gz will be empty
rule spades_assembly:
    input:
        fastq = "data/short_reads.filt.fastq.gz",
        long_reads = "data/long_reads.fastq.gz"
    output:
        fasta = "data/spades_assembly.fasta"
    threads:
         config["max_threads"]
    params:
         max_memory = config["max_memory"]
    conda:
        "../envs/spades.yaml"
    shell:
        """
        minimumsize=500000 && \
        actualsize=$(stat -c%s data/short_reads.filt.fastq.gz) && \
        if [ $actualsize -ge $minimumsize ]
        then
            spades.py --memory {params.max_memory} --meta --nanopore {input.long_reads} --12 {input.fastq} \
            -o data/spades_assembly -t {threads} -k 21,33,55,81,99,127 && \
            ln data/spades_assembly/scaffolds.fasta data/spades_assembly.fasta
        else
            touch {output.fasta}
        fi 
        """



# Short reads that did not map to the long read assembly are hybrid assembled with metaspades
# If no long reads were provided, long_reads.fastq.gz will be empty
rule spades_assembly_short:
    output:
        fasta = "data/final_contigs.fasta"
    threads:
         config["max_threads"]
    params:
         max_memory = config["max_memory"]
    conda:
        "../envs/spades.yaml"
    script:
        "../scripts/spades_assembly_short.py"


# Short reads are mapped to the spades assembly and jgi_summarize_bam_contig_depths from metabat
# used to calculate the mean coverage of the contigs. The coverage and assembly are then used to bin with metabat.
rule spades_assembly_coverage:
    input:
         fastq = "data/short_reads.filt.fastq.gz",
         fasta = "data/spades_assembly.fasta"
    output:
         assembly_cov = "data/short_read_assembly.cov"
    conda:
         "../envs/coverm.yaml"
    threads:
         config["max_threads"]
    shell:
        """
        coverm contig -m metabat -t {threads} -r {input.fasta} -i {input.fastq} > data/short_read_assembly.cov
        """

rule metabat_binning_short:
    input:
         assembly_cov = "data/short_read_assembly.cov",
         fasta = "data/spades_assembly.fasta"
    output:
         metabat_done = "data/metabat_bins/done"
    conda:
         "../envs/metabat2.yaml"
    threads:
         config["max_threads"]
    shell:
         """
         mkdir -p data/metabat_bins && \
         metabat --seed 89 --unbinned -m 1500 -l -i {input.fasta} -a {input.assembly_cov} \
         -o data/metabat_bins/binned_contigs && \
         touch data/metabat_bins/done
         """

# Long reads are mapped to the spades assembly
rule map_long_mega:
    input:
        fastq = "data/long_reads.fastq.gz",
        fasta = "data/spades_assembly.fasta"
    output:
        bam = "data/long_vs_mega.bam"
    threads:
        config["max_threads"]
    conda:
        "../envs/minimap2.yaml"
    shell:
        """
        minimap2 -t {threads} -ax map-ont -a {input.fasta} {input.fastq} |  samtools view -b |
        samtools sort -o {output.bam} - && \
        samtools index {output.bam}
        """
